name: Dizipall ve Diziyiizle Son Eklenen Dizileri Kontrol Etme

on:
  schedule:
    - cron: "0 */6 * * *"  # Her 6 saatte bir
  workflow_dispatch:

jobs:
  scrape:
    runs-on: ubuntu-latest

    steps:
      - name: Python'u Kur
        uses: actions/setup-python@v5
        with:
          python-version: "3.11"

      - name: Gerekli KÃ¼tÃ¼phaneleri YÃ¼kle
        run: |
          pip install requests beautifulsoup4

      - name: Scraper'Ä± Ã‡alÄ±ÅŸtÄ±r
        run: |
          python - <<EOF
          import requests
          from bs4 import BeautifulSoup

          # ----------------------------------------------------
          # 1) DIZIPALL
          domain_url = "https://raw.githubusercontent.com/zerodayip/domain/refs/heads/main/dizipall.txt"
          domain = requests.get(domain_url).text.strip()

          url = f"{domain}/kesfet"
          headers = {
              "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) "
                            "AppleWebKit/537.36 (KHTML, like Gecko) "
                            "Chrome/128.0.0.0 Safari/537.36",
              "Referer": domain
          }

          response = requests.get(url, headers=headers)

          if response.status_code == 200:
              soup = BeautifulSoup(response.text, "html.parser")
              print(f"ðŸŒ {domain}")

              items = soup.find_all("div", class_="filter-result-box")

              for item in items:
                  # âž¤ BaÅŸlÄ±k
                  h2 = item.find("h2")
                  title = h2.get_text(strip=True).upper() if h2 else "BÄ°LÄ°NMÄ°YOR"

                  # âž¤ YapÄ±m yÄ±lÄ± (bottom iÃ§indeki ilk p)
                  year = "BÄ°LÄ°NMÄ°YOR"
                  bottom = item.find("div", class_="filter-result-box-bottom")
                  if bottom:
                      year_li = bottom.find("p")
                      if year_li:
                          year = year_li.get_text(strip=True)

                  print(f"{title} - {year}")

              print("---------------------")
          else:
              print(f"{domain} isteÄŸi baÅŸarÄ±sÄ±z:", response.status_code)



          # ----------------------------------------------------
          # 2) DIZIYIIZLE
          domain_url2 = "https://raw.githubusercontent.com/zerodayip/domain/refs/heads/main/diziyiizle.txt"
          domain2 = requests.get(domain_url2).text.strip()

          url2 = f"{domain2}/kesfet-izle/"
          headers2 = {
              "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) "
                            "AppleWebKit/537.36 (KHTML, like Gecko) "
                            "Chrome/128.0.0.0 Safari/537.36",
              "Referer": domain2
          }

          response2 = requests.get(url2, headers=headers2)

          if response2.status_code == 200:
              soup2 = BeautifulSoup(response2.text, "html.parser")
              print(f"ðŸŒ {domain2}")

              cards = soup2.select("#seriesGrid a")

              for card in cards:
                  # âž¤ BaÅŸlÄ±k
                  title_tag = card.find("img")
                  title = title_tag.get("alt", "BÄ°LÄ°NMÄ°YOR").strip().upper() if title_tag else "BÄ°LÄ°NMÄ°YOR"

                  # âž¤ YapÄ±m yÄ±lÄ±
                  year = "BÄ°LÄ°NMÄ°YOR"
                  year_tag = card.find("div", class_="flex items-center space-x-2 text-sm text-gray-400")
                  if year_tag:
                      span = year_tag.find("span")
                      if span:
                          year = span.get_text(strip=True)

                  print(f"{title} - {year}")

              print("---------------------")
          else:
              print(f"{domain2} isteÄŸi baÅŸarÄ±sÄ±z:", response2.status_code)

          EOF
